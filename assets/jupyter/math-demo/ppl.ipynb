{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d71b510",
   "metadata": {},
   "source": [
    "**Perplexity（困惑度）**\n",
    "\n",
    "语言模型“平均分岔数”的度量：越小越好。直观地说，PPL ≈ 模型在每个位置上“平均有多少个等可能的选择”。\n",
    "\n",
    "给定长度为 $T$$ 的标注序列 $x_{1:T}$（通常是 token 序列），自回归 LM 的对数似然\n",
    "$$log p(x_{1:T})=\\sum_{t=1}^{T}\\log p(x_t\\mid x_{<t})$$\n",
    "\n",
    "交叉熵 / 负对数似然（单位：nats）\n",
    "$$\\text{NLL} = -\\frac{1}{T}\\sum_{t=1}^{T}\\log p(x_t\\mid x_{<t})$$\n",
    "\n",
    "Perplexity（自然对数制）\n",
    "$$\\mathrm{PPL}=\\exp(\\text{NLL})$$\n",
    "\n",
    "如果用的是 以 2 为底的交叉熵（bits-per-token, BPT）\n",
    "$$\\mathrm{PPL}=2^{\\text{BPT}}$$\n",
    "\n",
    "两者关系\n",
    "$$\\text{BPT}=\\text{NLL}/\\ln 2$$\n",
    "\n",
    "例子：平均 NLL = 1.2（nats）⇒ PPL = e^{1.2}\\approx 3.32。\n",
    "若 BPT = 1（每个 token 1 bit）⇒ PPL = 2^1=2。\n",
    "\n",
    "**训练和评测时怎么算**\n",
    "- **教师强制（teacher forcing）** 前向，拿到每个位置的预测分布；\n",
    "- 取目标 token 的 log 概率，累加得到总 NLL；\n",
    "- 用有效 token 数（排除 padding、被忽略标签）做平均：$\\text{NLL}_\\text{avg}=\\text{NLL}_\\text{sum}/T_\\text{valid}$；\n",
    "- PPL = $exp(NLL_avg)$；\n",
    "\n",
    "**注意事项**\n",
    "- 如果用 HuggingFace 模型直接返回的 loss（默认是 mean），需乘上本 batch 的有效 token 数再累计，最后除以全局 token 数再 exp；\n",
    "- token 粒度：PPL 与 分词器强相关（BPE / word / char）；跨模型 / 语料比较时要一致的分词方案；\n",
    "- 序列 / 批次加权：要按 token 总数加权，不能对 batch 级均值再做简单平均；\n",
    "- 忽略项：padding、被 mask 的标签（-100）不应计入分母；\n",
    "- 大多数深度学习框架的 CrossEntropy 使用自然对数，所以 ppl = exp(loss)；若你算的是 bits-per-token，就用 2**loss_bits；\n",
    "- 带标签平滑 / 类目加权时 PPL 不再等价于真实对数似然，比较需谨慎；\n",
    "- BERT 等双向 MLM 没有标准 PPL，可用 pseudo-perplexity（逐位 mask 评估）或改造成自回归评测；\n",
    "- PPL ≈ 1 几乎每步都非常确定（理想极限）；PPL ≈ 词表大小模型基本瞎猜；\n",
    "- 在同一数据与分词设定下，更低的 PPL 通常意味着更好的整体语言建模，但对下游生成质量仍需结合任务指标（如 Rouge / BLEU / human eval）；\n",
    "\n",
    "**PPL 以上的能力面**\n",
    "现代大模型评测更像一整套“可用性 + 可靠性 + 成本”的体检。\n",
    "\n",
    "- 能力面\n",
    "\t- 通识与推理：MMLU、HellaSwag、Winogrande、ARC；指标 = Accuracy / Exact-Match；\n",
    "\t- 数学：GSM8K、MATH；指标 = Accuracy、一步步推导是否自洽（用判据 / judge）；\n",
    "\t- 代码：HumanEval、MBPP、竞赛题；指标 = pass@k（建议 k= 1 / 5 / 10）；\n",
    "\t- 多轮与规划：多轮任务完成率、步骤一致性、死循环率；\n",
    "\t- 多语种 / 多模态：跨语言一致性、翻译质量（COMET / BLEU）、图表理解正确率；\n",
    "\n",
    "- 真实性与可溯源\n",
    "\t- 事实一致性 / 幻觉率：支持证据的比例、无依据断言占比（#unsupported claims / #claims）。\n",
    "\t- 带检索 / 长文问答（RAG）：答案与上下文的相关性 / 覆盖率 / 精确度（可用 RAGAS：answer-relevancy、context-precision / recall、groundedness）；\n",
    "\t- 引用合规：是否返回可点击来源，引用与答案是否匹配；\n",
    "\t- 数据污染检查：评测集与训练数据重叠率（n-gram / 哈希近邻）；\n",
    "\n",
    "- 指令遵循与工具使用\n",
    "\t- 格式遵循：JSON 有效率、Schema 合格率、函数调用参数正确率；\n",
    "\t- 工具 / RAG / 函数路由：是否在需要时调用工具、调用是否最小化次数、失败重试率；\n",
    "\t- 拒答与覆盖：该拒绝时拒绝率、应答时命中率（coverage）；\n",
    "\n",
    "- 长上下文与记忆\n",
    "\t- 长文利用：needle-in-a-haystack 命中率、跨段引用正确率；\n",
    "\t- 位置鲁棒：lost-in-the-middle 测试（信息放前 / 中 / 后的一致性）；\n",
    "\t- KV Cache 质量：极长生成的退化点、重复 / 游走率；\n",
    "\n",
    "- 安全、偏见与隐私\n",
    "\t- 安全对抗：越狱/Jailbreak 套件通过率、提示注入抵抗力。\n",
    "\t- 有害内容：毒性/仇恨/违法输出率（可对接外部判别器）。\n",
    "\t- 偏见/公平：不同群体/语言/方言的一致性（StereoSet 等）。\n",
    "\t- 隐私：PII 泄露率、训练样本记忆测验（membership inference）。\n",
    "\n",
    "- 稳定性与鲁棒性\n",
    "\t- 提示敏感度：同义改写 / 拼写噪声 / 格式扰动下性能跌幅；\n",
    "\t- 校准：置信度–正确率一致性（ECE、Brier Score）、可选择性回答（coverage-risk 曲线）；\n",
    "\t- 再现性：多随机种子方差、温度变化敏感度；\n",
    "\n",
    "- 体验与人评\n",
    "\t- 人类偏好：A / B 盲评胜率、ELO（如 Arena 风格）、帮助度 / 无害度 / 真实性三分法；\n",
    "\t- 对话体验：平均回合数、澄清次数、被动重复率、内容多样性（去重 n-gram 比例）；\n",
    "\n",
    "- 效率与成本\n",
    "\t- 延迟：TTFT / TTFTokens、p50 / p95；\n",
    "\t- 吞吐：tokens/s、并发下退化曲线；\n",
    "\t- 资源：显存占用、KV 内存随长度增长斜率、每 1k tokens 成本；\n",
    "\t- 稳定性：长生成超时率、中断 / 重试率；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca194d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL = 18.65326690673828\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ce = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction='sum')\n",
    "vocab_size = 10\n",
    "model = torch.nn.Linear(100, vocab_size)\n",
    "\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seq_len=10):\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.randint(0, vocab_size, (self.seq_len,), dtype=torch.float32),\n",
    "            'attn_mask': torch.ones(self.seq_len),\n",
    "            'labels': torch.randint(0, vocab_size, (self.seq_len,))\n",
    "        }\n",
    "\n",
    "dataset = DummyDataset(seq_len=100)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "total_nll, total_tok = 0.0, 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids']\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        hidden = input_ids.view(batch_size * seq_len, -1)\n",
    "        hidden = hidden.mean(dim=1, keepdim=True).expand(-1, 100)\n",
    "        logits_flat = model(hidden)\n",
    "        logits = logits_flat.view(batch_size, seq_len, vocab_size)\n",
    "        nll = ce(logits.view(-1, logits.size(-1)), batch['labels'].view(-1))\n",
    "        total_nll += nll.item()\n",
    "        total_tok += (batch['labels'] != -100).sum().item()\n",
    "\n",
    "ppl = torch.exp(torch.tensor(total_nll / total_tok)).item()\n",
    "print(\"PPL =\", ppl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
