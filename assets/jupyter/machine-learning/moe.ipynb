{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b248d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9241f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "h = C // 2\n",
    "\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "Wq = nn.Linear(C, h, bias=False)\n",
    "Wk = nn.Linear(C, h, bias=False)\n",
    "Wv = nn.Linear(C, h, bias=False)\n",
    "\n",
    "q = Wq(x)\n",
    "k = Wk(x)\n",
    "attn = q @ k.transpose(-2, -1) * h**-0.5\n",
    "attn = attn.masked_fill(torch.tril(torch.ones(T, T)) == 0, float('-inf'))\n",
    "attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "v = Wv(x)\n",
    "out = attn @ v\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d3043e",
   "metadata": {},
   "source": [
    "Below we implement MoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14b3bf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Head(\n",
       "  (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "  (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "  (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(64, 16, bias=False)\n",
    "        self.query = nn.Linear(64, 16, bias=False)\n",
    "        self.value = nn.Linear(64, 16, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(8, 8)))\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "head = Head()\n",
    "head.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f2a1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(16) for _ in range(4)])\n",
    "        self.proj = nn.Linear(64, 64)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "020ce0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    \"\"\" An MLP is a simple linear layer followed by a non-linearity i.e. each Expert \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(64, 4 * 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * 64, 64),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04d7a2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 2]),\n",
       " tensor([[[1, 2],\n",
       "          [2, 0],\n",
       "          [1, 2],\n",
       "          [1, 3],\n",
       "          [1, 3],\n",
       "          [3, 0],\n",
       "          [2, 3],\n",
       "          [0, 2]],\n",
       " \n",
       "         [[1, 2],\n",
       "          [2, 0],\n",
       "          [1, 3],\n",
       "          [1, 2],\n",
       "          [0, 3],\n",
       "          [3, 0],\n",
       "          [1, 2],\n",
       "          [2, 3]]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_out = torch.randn(2, 8, 64)\n",
    "gate = nn.Linear(64, 4)\n",
    "logits = gate(mha_out)\n",
    "top_k_logits, top_k_indices = logits.topk(2, dim=-1)\n",
    "top_k_logits.shape, top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f95f28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   -inf,  0.5624, -0.2478,    -inf],\n",
       "         [ 0.9851,    -inf,  1.0902,    -inf],\n",
       "         [   -inf, -0.2416, -0.2549,    -inf],\n",
       "         [   -inf,  0.8075,    -inf,  0.4231],\n",
       "         [   -inf,  0.9113,    -inf,  0.2213],\n",
       "         [-0.1508,    -inf,    -inf,  0.5258],\n",
       "         [   -inf,    -inf,  1.7084,  0.9629],\n",
       "         [ 0.2472,    -inf,  0.1298,    -inf]],\n",
       "\n",
       "        [[   -inf,  0.3157,  0.1252,    -inf],\n",
       "         [ 0.0088,    -inf,  0.1553,    -inf],\n",
       "         [   -inf,  1.2441,    -inf,  0.1329],\n",
       "         [   -inf,  1.1404,  0.8150,    -inf],\n",
       "         [ 0.2541,    -inf,    -inf, -0.1712],\n",
       "         [ 0.0091,    -inf,    -inf,  0.1471],\n",
       "         [   -inf,  0.7702,  0.6067,    -inf],\n",
       "         [   -inf,    -inf,  0.2182, -0.0720]]], grad_fn=<ScatterBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.full_like(logits, float('-inf'))\n",
    "sparse_logits = zeros.scatter(-1, top_k_indices, top_k_logits)\n",
    "sparse_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a61eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.6922, 0.3078, 0.0000],\n",
       "         [0.4737, 0.0000, 0.5263, 0.0000],\n",
       "         [0.0000, 0.5033, 0.4967, 0.0000],\n",
       "         [0.0000, 0.5949, 0.0000, 0.4051],\n",
       "         [0.0000, 0.6660, 0.0000, 0.3340],\n",
       "         [0.3370, 0.0000, 0.0000, 0.6630],\n",
       "         [0.0000, 0.0000, 0.6782, 0.3218],\n",
       "         [0.5293, 0.0000, 0.4707, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.5475, 0.4525, 0.0000],\n",
       "         [0.4634, 0.0000, 0.5366, 0.0000],\n",
       "         [0.0000, 0.7524, 0.0000, 0.2476],\n",
       "         [0.0000, 0.5806, 0.4194, 0.0000],\n",
       "         [0.6048, 0.0000, 0.0000, 0.3952],\n",
       "         [0.4655, 0.0000, 0.0000, 0.5345],\n",
       "         [0.0000, 0.5408, 0.4592, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5720, 0.4280]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out = F.softmax(sparse_logits, dim=-1)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a796f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopkRouter(nn.Module):\n",
    "    def __init__(self, top_k=2):\n",
    "        super(TopkRouter, self).__init__()\n",
    "        self.top_k = top_k\n",
    "        self.linear = nn.Linear(64, 4)\n",
    "    \n",
    "    def forward(self, mha_out):\n",
    "        logits = self.linear(mha_out)\n",
    "        top_k_logits, indices = logits.topk(self.top_k, dim=-1)\n",
    "        zeros = torch.full_like(logits, float('-inf'))\n",
    "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
    "        router_output = F.softmax(sparse_logits, dim=-1)\n",
    "        return router_output, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4dcd88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 4]),\n",
       " tensor([[[0.4396, 0.0000, 0.5604, 0.0000],\n",
       "          [0.0000, 0.5184, 0.4816, 0.0000],\n",
       "          [0.5368, 0.4632, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5307, 0.4693],\n",
       "          [0.4503, 0.0000, 0.5497, 0.0000],\n",
       "          [0.8090, 0.0000, 0.1910, 0.0000],\n",
       "          [0.2159, 0.0000, 0.0000, 0.7841],\n",
       "          [0.5806, 0.0000, 0.4194, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.4851, 0.5149, 0.0000],\n",
       "          [0.0000, 0.4580, 0.0000, 0.5420],\n",
       "          [0.0000, 0.4375, 0.5625, 0.0000],\n",
       "          [0.0000, 0.0000, 0.6797, 0.3203],\n",
       "          [0.0000, 0.0000, 0.6767, 0.3233],\n",
       "          [0.0000, 0.0000, 0.5312, 0.4688],\n",
       "          [0.7180, 0.2820, 0.0000, 0.0000],\n",
       "          [0.0000, 0.5857, 0.0000, 0.4143]],\n",
       " \n",
       "         [[0.0000, 0.4748, 0.5252, 0.0000],\n",
       "          [0.4327, 0.5673, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5812, 0.4188],\n",
       "          [0.6178, 0.0000, 0.0000, 0.3822],\n",
       "          [0.0000, 0.5805, 0.4195, 0.0000],\n",
       "          [0.5259, 0.0000, 0.0000, 0.4741],\n",
       "          [0.5692, 0.4308, 0.0000, 0.0000],\n",
       "          [0.7383, 0.0000, 0.0000, 0.2617]],\n",
       " \n",
       "         [[0.4135, 0.0000, 0.0000, 0.5865],\n",
       "          [0.7186, 0.0000, 0.2814, 0.0000],\n",
       "          [0.6145, 0.0000, 0.3855, 0.0000],\n",
       "          [0.0000, 0.4961, 0.5039, 0.0000],\n",
       "          [0.4567, 0.0000, 0.0000, 0.5433],\n",
       "          [0.4048, 0.0000, 0.0000, 0.5952],\n",
       "          [0.3559, 0.6441, 0.0000, 0.0000],\n",
       "          [0.5120, 0.4880, 0.0000, 0.0000]]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[[2, 0],\n",
       "          [1, 2],\n",
       "          [0, 1],\n",
       "          [2, 3],\n",
       "          [2, 0],\n",
       "          [0, 2],\n",
       "          [3, 0],\n",
       "          [0, 2]],\n",
       " \n",
       "         [[2, 1],\n",
       "          [3, 1],\n",
       "          [2, 1],\n",
       "          [2, 3],\n",
       "          [2, 3],\n",
       "          [2, 3],\n",
       "          [0, 1],\n",
       "          [1, 3]],\n",
       " \n",
       "         [[2, 1],\n",
       "          [1, 0],\n",
       "          [2, 3],\n",
       "          [0, 3],\n",
       "          [1, 2],\n",
       "          [0, 3],\n",
       "          [0, 1],\n",
       "          [0, 3]],\n",
       " \n",
       "         [[3, 0],\n",
       "          [0, 2],\n",
       "          [0, 2],\n",
       "          [2, 1],\n",
       "          [3, 0],\n",
       "          [3, 0],\n",
       "          [1, 0],\n",
       "          [0, 1]]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_output = torch.randn(4, 8, 64) \n",
    "top_k_gate = TopkRouter()\n",
    "gating_output, indices = top_k_gate(mha_output)\n",
    "gating_output.shape, gating_output, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1d41296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyTopkRouter(nn.Module):\n",
    "    def __init__(self, top_k=2):\n",
    "        super(NoisyTopkRouter, self).__init__()\n",
    "        self.top_k = top_k\n",
    "        self.topkroute_linear = nn.Linear(64, 4)\n",
    "        self.noise_linear = nn.Linear(64, 4)\n",
    "\n",
    "    \n",
    "    def forward(self, mha_output):\n",
    "        logits = self.topkroute_linear(mha_output)\n",
    "        noise_logits = self.noise_linear(mha_output)\n",
    "\n",
    "        #Adding scaled unit gaussian noise to the logits\n",
    "        noise = torch.randn_like(logits) * F.softplus(noise_logits)\n",
    "        noisy_logits = logits + noise\n",
    "\n",
    "        top_k_logits, indices = noisy_logits.topk(self.top_k, dim=-1)\n",
    "        zeros = torch.full_like(noisy_logits, float('-inf'))\n",
    "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
    "        router_output = F.softmax(sparse_logits, dim=-1)\n",
    "        return router_output, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "176e0d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-3): 4 x Expert(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ModuleList([Expert() for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee8ba982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 8, 64) \n",
    "x.view(-1, x.size(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "055d7f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 4])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router = NoisyTopkRouter()\n",
    "gating_output, indices = router(x)\n",
    "gating_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8cd3cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 64])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = torch.zeros_like(x)\n",
    "final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "527e19fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 4]),\n",
       " tensor([0.4768, 0.0000, 0.0000, 0.5232], grad_fn=<SelectBackward0>),\n",
       " tensor([3, 0]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
    "flat_gating_output.shape, flat_gating_output[0], indices[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848d43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  True,  True,  True,  True, False],\n",
       "        [ True, False,  True,  True, False,  True, False,  True],\n",
       "        [ True, False, False, False,  True,  True,  True,  True],\n",
       "        [ True,  True,  True, False,  True, False,  True, False]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(indices == 3).shape\n",
    "(indices == 3).any(dim=-1) # B, T -> True means expert 3 is activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c24b6e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(indices == 3).any(dim=-1).view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "28e2dd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_mask = (indices == 0).any(dim=-1).view(-1)\n",
    "flat_x = x.view(-1, x.size(-1))\n",
    "flat_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a12b59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 64])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_x[flat_mask == True].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "04fb4d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5232],\n",
       "        [0.0000],\n",
       "        [0.3629],\n",
       "        [0.0000],\n",
       "        [0.4361],\n",
       "        [0.0000],\n",
       "        [0.7600],\n",
       "        [0.0000],\n",
       "        [0.6714],\n",
       "        [0.8067],\n",
       "        [0.2371],\n",
       "        [0.0000],\n",
       "        [0.5308],\n",
       "        [0.0000]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gating_scores = flat_gating_output[flat_mask, 3].unsqueeze(1)\n",
    "gating_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "81195748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[3, 4, 5, 6], [0, 1, 2, 1]])\n",
    "x[[True,False], 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ed5ba210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 64])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert = Expert()\n",
    "expert_output = expert(flat_x[flat_mask])\n",
    "expert_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "67dc1220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 64])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(expert_output * gating_scores).squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "58b9d940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 64])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 8, 64) \n",
    "final_out = torch.zeros_like(x)\n",
    "final_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3611209a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False,  True, False, False, False, False],\n",
       "        [False,  True, False, False, False,  True,  True,  True],\n",
       "        [False, False,  True, False,  True,  True, False, False],\n",
       "        [False,  True, False, False, False,  True,  True,  True]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_mask = (indices == 0).any(dim=-1)\n",
    "expert_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1356d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 64])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out[expert_mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b7e5db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMoE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SparseMoE, self).__init__()\n",
    "        self.router = NoisyTopkRouter(64, 4, 2)\n",
    "        self.experts = nn.ModuleList([Expert() for _ in range(4)])\n",
    "        self.top_k = 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        gating_output, indices = self.router(x)\n",
    "        final_output = torch.zeros_like(x)\n",
    "\n",
    "        # Reshape inputs for batch processing\n",
    "        flat_x = x.view(-1, x.size(-1))\n",
    "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))\n",
    "\n",
    "        # Process each expert in parallel\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            # Create a mask for the inputs where the current expert is in top-k\n",
    "            expert_mask = (indices == i).any(dim=-1)\n",
    "            flat_mask = expert_mask.view(-1)\n",
    "\n",
    "            if flat_mask.any():\n",
    "                expert_input = flat_x[flat_mask]\n",
    "                expert_output = expert(expert_input)\n",
    "\n",
    "                # Extract and apply gating scores\n",
    "                gating_scores = flat_gating_output[flat_mask, i].unsqueeze(1)\n",
    "                weighted_output = expert_output * gating_scores\n",
    "\n",
    "                # Update final output additively by indexing and adding\n",
    "                final_output[expert_mask] += weighted_output.squeeze(1)\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "55a47385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention()\n",
    "        self.smoe = SparseMoE()\n",
    "        self.ln1 = nn.LayerNorm(64)\n",
    "        self.ln2 = nn.LayerNorm(64)\n",
    "\n",
    "    def foward(self, x):\n",
    "        x = x + self.mha(self.ln1(x))\n",
    "        x = x + self.smoe(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b44e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
