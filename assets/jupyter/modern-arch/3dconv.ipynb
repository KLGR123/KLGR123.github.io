{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_ds = datasets.MNIST(root='./data', train=True,  download=False, transform=transform)\n",
    "test_ds = datasets.MNIST(root='./data', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b62a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(train_loader))\n",
    "imgs.shape, imgs.nelement(), labels, set(sorted(labels.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d841da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0][0], cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 8\n",
    "in_channels = 1 # grey images\n",
    "kernel_size = 3\n",
    "\n",
    "weight = torch.randn((out_channels, in_channels, kernel_size, kernel_size), dtype=torch.float) * 0.1\n",
    "bias = torch.zeros(out_channels)\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kh, Kw = 4, 6\n",
    "Sh, Sw = 2, 1\n",
    "Ph, Pw = 2, 3\n",
    "\n",
    "B, C, H, W = 2, 3, 27, 32\n",
    "\n",
    "unfold = torch.nn.Unfold(kernel_size=(Kh, Kw), stride=(Sh, Sw), padding=(Ph, Pw))\n",
    "input = torch.randn(B, C, H, W)\n",
    "output = unfold(input)\n",
    "\n",
    "print(output.shape)\n",
    "output.shape == torch.Size([B, C*Kh*Kw, ((H+2*Ph-Kh) // Sh + 1) * ((W+2*Pw-Kw) // Sw + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = F.unfold(imgs, kernel_size=(3,3), stride=1)\n",
    "patches.shape, patches.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_flat = weight.view(8, in_channels*(kernel_size**2))\n",
    "w_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d796fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = w_flat @ patches + bias.unsqueeze(1) # [64, 8, 9] * [64, 9, 676] -> [64, 8, 676] + [8, 1]\n",
    "conv.shape, conv.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90466db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover the conv to feature map (B, C', H', W')\n",
    "conv = conv.view(conv.shape[0], 8, 26, 26)\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = F.relu(conv)\n",
    "conv = F.max_pool2d(conv, kernel_size=2)\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = conv.view(conv.shape[0], -1)\n",
    "conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_out = torch.randn(8*13*13, 10)\n",
    "logits = conv @ w_out\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.randn(8, 1, 3, 3) * 0.1)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(8))\n",
    "        self.fc = torch.nn.Linear(8 * 13 * 13, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = F.unfold(x, kernel_size=3, stride=1)\n",
    "        w_flat = self.weight.view(8, -1)\n",
    "\n",
    "        conv = w_flat @ patches + self.bias.unsqueeze(1)\n",
    "\n",
    "        B = x.size(0)\n",
    "        conv = conv.view(B, 8, 26, 26)\n",
    "\n",
    "        conv = F.relu(conv)\n",
    "        conv = F.max_pool2d(conv, kernel_size=2)\n",
    "\n",
    "        conv = conv.view(B, -1)\n",
    "        out = self.fc(conv)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ScratchCNN().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "imgs, labels = imgs.to(device), labels.to(device)\n",
    "logits = model(imgs)\n",
    "logits.shape, labels.shape\n",
    "loss = criterion(logits, labels)\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d017d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda04e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        # wandb.log({\n",
    "        #     'train_loss': loss,\n",
    "        #     'lr': optim.param_groups[0]['lr']\n",
    "        # })\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}  Train Loss: {total_loss/len(train_loader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb57399",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "        # acc = correct / len(test_loader.dataset)\n",
    "        # wandb.log({\n",
    "        #     'val_acc': acc,\n",
    "        # })\n",
    "\n",
    "acc = correct / len(test_loader.dataset)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0e9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(test_loader))\n",
    "imgs = imgs[:5]\n",
    "labels = labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056402fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b871b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b912ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf2bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(imgs)\n",
    "    \n",
    "pred = F.softmax(logits, dim=1)\n",
    "plt.figure(figsize=(8,2))\n",
    "plt.imshow(pred, cmap='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b17af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project='scratch-cnn', name='exp2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186d4584",
   "metadata": {},
   "source": [
    "let's use torch.nn.conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c916edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e033addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_ds = datasets.MNIST(root='./data', train=True,  download=False, transform=transform)\n",
    "test_ds  = datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e30098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(8 * 14 * 14, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x) # [B,8,28,28]\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2) # [B,8,14,14]\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.fc(x) # [B,10]\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c4e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Train Loss: 0.2698\n",
      "Epoch 2/2, Train Loss: 0.1081\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    avg_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ee23d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.19%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == labels).sum().item()\n",
    "acc = correct / len(test_loader.dataset)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca451f0",
   "metadata": {},
   "source": [
    "now we try with 3d conv and 2+1d conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0a1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f119f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "clip_len = 16\n",
    "height = 112\n",
    "width = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a88e57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 16, 112, 112])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_data = torch.randn(batch_size, 3, clip_len, height, width)\n",
    "random_data.shape # B, C, T, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cafdc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.9802e-08) tensor(1.0328)\n",
      "tensor(-1.6764e-08) tensor(1.0010)\n",
      "tensor(1.2772e-08) tensor(1.0000)\n",
      "tensor(2.6609e-10) tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(16, 512)\n",
    "    bn = nn.BatchNorm1d(512)\n",
    "    out = bn(x)\n",
    "    print(out[:,0].mean(), out[:,0].std())\n",
    "\n",
    "    x = torch.randn(16, 512)\n",
    "    ln = nn.LayerNorm(512)\n",
    "    out = ln(x)\n",
    "    print(out[0,:].mean(), out[0,:].std())\n",
    "\n",
    "    x = torch.randn(16, 3, 32, 28) # 4D\n",
    "    bn = nn.BatchNorm2d(3)\n",
    "    out = bn(x)\n",
    "    print(out[:,0].mean(), out[:,0].std())\n",
    "\n",
    "    x = torch.randn(16, 3, 512, 32, 28) # 5D\n",
    "    bn = nn.BatchNorm3d(3)\n",
    "    out = bn(x)\n",
    "    print(out[:,0].mean(), out[:,0].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75d2b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1))\n",
    "bn1 = nn.BatchNorm3d(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69cd8cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 16, 112, 112])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random_data\n",
    "x = conv1(x)\n",
    "x = bn1(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79050a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8, 56, 56])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool1 = nn.MaxPool3d(kernel_size=(2,2,2), stride=(2,2,2))\n",
    "x = pool1(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d90574ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 8, 56, 56])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2 = nn.Conv3d(in_channels=16, out_channels=32, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1))\n",
    "bn2 = nn.BatchNorm3d(32)\n",
    "\n",
    "x = conv2(x)\n",
    "x = bn2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5333369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 4, 28, 28])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2 = nn.MaxPool3d(kernel_size=(2,2,2), stride=(2,2,2))\n",
    "x = pool2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7106e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 1, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_pool = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "x = global_pool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f73fab2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(x.size(0), -1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f6a87f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(32, 10)\n",
    "x = fc(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab13ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(16, 3, 16, 112, 112)\n",
    "spatial_conv = nn.Conv3d(3, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
    "bn1 = nn.BatchNorm3d(16)\n",
    "temp_conv = nn.Conv3d(16, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
    "bn2 = nn.BatchNorm3d(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29d2b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv3d(3, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "  (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Conv3d(16, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "  (3): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2plus1d = nn.Sequential(spatial_conv, bn1, temp_conv, bn2)\n",
    "r2plus1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b4093a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 16, 112, 112])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2plus1d(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff3014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
