{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb006d1-056f-497a-b5f4-1e082c7bdfe2",
   "metadata": {},
   "source": [
    "实现一个单机简化版的 Top-k MoE-FFN，带 capacity 管理。不含分布式通信，但保持真实的数据流：route -> dispatch -> expert -> combine。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14d7920-dd9f-43f7-be4c-479b81b9fd0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:44.474678Z",
     "iopub.status.busy": "2025-11-06T11:09:44.474273Z",
     "iopub.status.idle": "2025-11-06T11:09:45.799496Z",
     "shell.execute_reply": "2025-11-06T11:09:45.799103Z",
     "shell.execute_reply.started": "2025-11-06T11:09:44.474644Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TopKRouter(nn.Module):\n",
    "    def __init__(self, d_model, n_expert, k=2, lb_coef=0.01):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, n_expert, bias=False)\n",
    "        self.n_expert = n_expert\n",
    "        self.k = k\n",
    "        self.lb_coef = lb_coef\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        logits = self.proj(x) \n",
    "        B, T, E = logits.shape\n",
    "\n",
    "        gate = F.softmax(logits, dim=-1)\n",
    "        topk_val, topk_idx = torch.topk(gate, k=self.k, dim=-1)\n",
    "        combine = topk_val / (topk_val.sum(dim=-1, keepdim=True) + 1e-9) # (B, T, k)\n",
    "        \n",
    "        expert_prob_mean = gate.mean(dim=(0,1))\n",
    "        lb_loss = self.lb_coef * (expert_prob_mean * self.n_expert).var()\n",
    "        return topk_idx, combine, lb_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4d05f5-07fd-4c65-b615-5c9ddf6f1340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:45.800443Z",
     "iopub.status.busy": "2025-11-06T11:09:45.800184Z",
     "iopub.status.idle": "2025-11-06T11:09:45.810079Z",
     "shell.execute_reply": "2025-11-06T11:09:45.809746Z",
     "shell.execute_reply.started": "2025-11-06T11:09:45.800424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2, 0],\n",
       "          [0, 1],\n",
       "          [2, 0],\n",
       "          [0, 1],\n",
       "          [1, 2],\n",
       "          [0, 1],\n",
       "          [1, 0],\n",
       "          [1, 0],\n",
       "          [2, 0],\n",
       "          [1, 0]],\n",
       " \n",
       "         [[1, 2],\n",
       "          [0, 2],\n",
       "          [0, 1],\n",
       "          [1, 2],\n",
       "          [2, 1],\n",
       "          [1, 0],\n",
       "          [1, 2],\n",
       "          [2, 1],\n",
       "          [0, 2],\n",
       "          [1, 0]]]),\n",
       " tensor([[[0.7276, 0.2724],\n",
       "          [0.5056, 0.4944],\n",
       "          [0.7670, 0.2330],\n",
       "          [0.6169, 0.3831],\n",
       "          [0.5569, 0.4431],\n",
       "          [0.6603, 0.3397],\n",
       "          [0.5663, 0.4337],\n",
       "          [0.5104, 0.4896],\n",
       "          [0.5983, 0.4017],\n",
       "          [0.6073, 0.3927]],\n",
       " \n",
       "         [[0.7937, 0.2063],\n",
       "          [0.7699, 0.2301],\n",
       "          [0.5613, 0.4387],\n",
       "          [0.5443, 0.4557],\n",
       "          [0.6573, 0.3427],\n",
       "          [0.7773, 0.2227],\n",
       "          [0.5107, 0.4893],\n",
       "          [0.6470, 0.3530],\n",
       "          [0.7049, 0.2951],\n",
       "          [0.5109, 0.4891]]], grad_fn=<DivBackward0>),\n",
       " tensor(3.9716e-05))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router = TopKRouter(128, 3, k=2)\n",
    "x = torch.randn(2, 10, 128)\n",
    "topk_idx, combine, lb_loss = router(x)\n",
    "topk_idx, combine, lb_loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e26d4e-fdfc-4c6c-a407-ce3c052441a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:45.810792Z",
     "iopub.status.busy": "2025-11-06T11:09:45.810595Z",
     "iopub.status.idle": "2025-11-06T11:09:45.813679Z",
     "shell.execute_reply": "2025-11-06T11:09:45.813306Z",
     "shell.execute_reply.started": "2025-11-06T11:09:45.810775Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExpertFFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.up = nn.Linear(d_model, d_ff, bias=False)\n",
    "        self.down = nn.Linear(d_ff, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        out = self.down(F.gelu(self.up(x)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14515e5f-a562-43e8-aa14-0b3768346909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:45.814406Z",
     "iopub.status.busy": "2025-11-06T11:09:45.814209Z",
     "iopub.status.idle": "2025-11-06T11:09:45.822016Z",
     "shell.execute_reply": "2025-11-06T11:09:45.821498Z",
     "shell.execute_reply.started": "2025-11-06T11:09:45.814390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_fnn = ExpertFFN(128, 512)\n",
    "x = torch.randn(2, 10, 128)\n",
    "expert_fnn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a969fcc-25e3-4a0f-b967-05d9cf9b485b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:45.822990Z",
     "iopub.status.busy": "2025-11-06T11:09:45.822690Z",
     "iopub.status.idle": "2025-11-06T11:09:45.849284Z",
     "shell.execute_reply": "2025-11-06T11:09:45.848966Z",
     "shell.execute_reply.started": "2025-11-06T11:09:45.822958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router = TopKRouter(128, 32, k=2, lb_coef=0.02)\n",
    "experts = nn.ModuleList([ExpertFFN(128, 512) for _ in range(32)])\n",
    "2 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbcf3456-3eec-47f9-8faa-7d8166b6e01c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:26:14.533599Z",
     "iopub.status.busy": "2025-11-06T11:26:14.533308Z",
     "iopub.status.idle": "2025-11-06T11:26:14.541352Z",
     "shell.execute_reply": "2025-11-06T11:26:14.540895Z",
     "shell.execute_reply.started": "2025-11-06T11:26:14.533571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(64, 100, 128)\n",
    "W = torch.randn(128, 128)\n",
    "y = x @ W\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e088b9-4028-44db-95b2-446f32926bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:45.850618Z",
     "iopub.status.busy": "2025-11-06T11:09:45.850416Z",
     "iopub.status.idle": "2025-11-06T11:09:45.857036Z",
     "shell.execute_reply": "2025-11-06T11:09:45.856618Z",
     "shell.execute_reply.started": "2025-11-06T11:09:45.850601Z"
    }
   },
   "outputs": [],
   "source": [
    "B, T, C = x.shape\n",
    "device = x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2eaf523-f56e-430a-99ea-a8780d37da68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:45.857704Z",
     "iopub.status.busy": "2025-11-06T11:09:45.857569Z",
     "iopub.status.idle": "2025-11-06T11:09:45.862106Z",
     "shell.execute_reply": "2025-11-06T11:09:45.861658Z",
     "shell.execute_reply.started": "2025-11-06T11:09:45.857687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2025e-06, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_idx, combine, lb_loss = router(x) # (B, T, k), (B, T, k), scalar\n",
    "lb_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe6b8e2-24e1-4622-89e7-aa105b9b0a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:45.863101Z",
     "iopub.status.busy": "2025-11-06T11:09:45.862739Z",
     "iopub.status.idle": "2025-11-06T11:09:45.865739Z",
     "shell.execute_reply": "2025-11-06T11:09:45.865247Z",
     "shell.execute_reply.started": "2025-11-06T11:09:45.863077Z"
    }
   },
   "outputs": [],
   "source": [
    "x_flat = x.reshape(B * T, -1)\n",
    "idx_flat = topk_idx.reshape(B * T, -1)\n",
    "w_flat = combine.reshape(B * T, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7378e-ff20-4569-95f4-fdaf3437aea7",
   "metadata": {},
   "source": [
    "capacity 计算。每个专家最多接收 tokens_per_exp * capacity_factor 个 token。统计每个专家被路由到的 token 总数（按 top-k 计数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53d080e-d8d3-4e6b-862f-b4a1cae001e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:49.960082Z",
     "iopub.status.busy": "2025-11-06T11:09:49.959764Z",
     "iopub.status.idle": "2025-11-06T11:09:49.965661Z",
     "shell.execute_reply": "2025-11-06T11:09:49.965287Z",
     "shell.execute_reply.started": "2025-11-06T11:09:49.960061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([402, 380, 455, 449, 405, 382, 327, 376, 348, 487, 410, 445, 375, 455,\n",
       "         359, 432, 411, 456, 407, 360, 377, 390, 355, 354, 449, 417, 331, 415,\n",
       "         342, 373, 460, 416], dtype=torch.int32),\n",
       " 420,\n",
       " tensor([False, False,  True,  True, False, False, False, False, False,  True,\n",
       "         False,  True, False,  True, False,  True, False,  True, False, False,\n",
       "         False, False, False, False,  True, False, False, False, False, False,\n",
       "          True, False]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capacity_factor = 1.05\n",
    "\n",
    "with torch.no_grad():\n",
    "    counts = torch.zeros(32, device=device, dtype=torch.int32)\n",
    "    for e in range(32):\n",
    "        counts[e] = (idx_flat == e).sum()\n",
    "\n",
    "    expected = (B * T) * (2 / 32)\n",
    "    capacity = int(capacity_factor * expected)\n",
    "\n",
    "counts, capacity, (counts > capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2139f178-efd1-4ff4-9d59-c83368507d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:09:50.258560Z",
     "iopub.status.busy": "2025-11-06T11:09:50.258285Z",
     "iopub.status.idle": "2025-11-06T11:09:50.588132Z",
     "shell.execute_reply": "2025-11-06T11:09:50.587797Z",
     "shell.execute_reply.started": "2025-11-06T11:09:50.258540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(31.5), np.float64(0.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAAjCAYAAAAJ6AlIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAN1JREFUeJzt3TEKwzAQAMEo+P9fVn4QjEU4ws7UhpOlZlFhr733fgEAWe/pBQAAs8QAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4q67D661frmOryY/kjj53v/q9LxO9tzs1myeOTkz5/XM5J7fme1mAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDc2pP/BwYAxrkZAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIC4D7VEIz9t3+PeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mask = counts > capacity\n",
    "mask = mask.unsqueeze(1).T\n",
    "plt.imshow(mask, cmap=\"cubehelix\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8767ff-da4e-4804-8a51-3d6b7d4d4c89",
   "metadata": {},
   "source": [
    "接下来，为每个专家分配一个缓冲区；实际分布式里会做 all-to-all，且按 capacity pack。\n",
    "\n",
    "简化打包，溢出的丢弃；真实实现可 reroute/overflow 策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc2ad530-266f-4091-ae0a-c35ad54e4669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:11:09.038781Z",
     "iopub.status.busy": "2025-11-06T11:11:09.038321Z",
     "iopub.status.idle": "2025-11-06T11:11:09.321700Z",
     "shell.execute_reply": "2025-11-06T11:11:09.321310Z",
     "shell.execute_reply.started": "2025-11-06T11:11:09.038744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([402, 380, 420, 420, 405, 382, 327, 376, 348, 420, 410, 420, 375, 420,\n",
      "        359, 420, 411, 420, 407, 360, 377, 390, 355, 354, 420, 417, 331, 415,\n",
      "        342, 373, 420, 416])\n",
      "overflowed tokens: 308\n"
     ]
    }
   ],
   "source": [
    "expert_inputs = [[] for _ in range(32)]\n",
    "expert_weights = [[] for _ in range(32)]\n",
    "expert_pos = [[] for _ in range(32)]\n",
    "capacity_used = [0 for _ in range(32)]\n",
    "\n",
    "for n in range(B * T):\n",
    "    for k in range(2):\n",
    "        e = int(idx_flat[n, k])\n",
    "        if capacity_used[e] < capacity:\n",
    "            expert_inputs[e].append(x_flat[n:n+1, :])  # [1, D]\n",
    "            expert_weights[e].append(w_flat[n, k:k+1]) # [1]\n",
    "            expert_pos[e].append((n, k))\n",
    "            capacity_used[e] += 1\n",
    "        else:\n",
    "            pass # here we simplified\n",
    "\n",
    "print(torch.tensor(capacity_used))\n",
    "print(\"overflowed tokens:\", B * T * 2 - sum(capacity_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eefb484b-82f6-4192-bfb7-bb9665576fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:11:09.418538Z",
     "iopub.status.busy": "2025-11-06T11:11:09.418114Z",
     "iopub.status.idle": "2025-11-06T11:11:09.892408Z",
     "shell.execute_reply": "2025-11-06T11:11:09.892053Z",
     "shell.execute_reply.started": "2025-11-06T11:11:09.418518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 100, 128]), tensor(3.2025e-06, grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_flat = torch.zeros(B*T, C, dtype=torch.float64, device=device)\n",
    "for e in range(32):\n",
    "    if len(expert_inputs[e]) == 0:\n",
    "        continue\n",
    "    inp = torch.cat(expert_inputs[e], dim=0) # [s_e, C]\n",
    "    wts = torch.cat(expert_weights[e], dim=0) # [s_e, 1]\n",
    "    y = experts[e](inp) # [s_e, C]\n",
    "    for i, (n, k) in enumerate(expert_pos[e]):\n",
    "        out_flat[n] += wts[i] * y[i]\n",
    "\n",
    "out = out_flat.reshape(B, T, C)\n",
    "aux_loss = lb_loss\n",
    "out.shape, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8d2589-fc3c-480b-bfa8-4c84b62994ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:14:56.743496Z",
     "iopub.status.busy": "2025-11-06T11:14:56.743155Z",
     "iopub.status.idle": "2025-11-06T11:15:05.296941Z",
     "shell.execute_reply": "2025-11-06T11:15:05.296104Z",
     "shell.execute_reply.started": "2025-11-06T11:14:56.743476Z"
    }
   },
   "outputs": [],
   "source": [
    "y = torch.randn(64, 100, 128).detach()\n",
    "loss = ((out - y) ** 2).mean() + aux_loss\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "178e908f-77f2-4bfa-8dfb-901a6e67e0d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:17:38.187748Z",
     "iopub.status.busy": "2025-11-06T11:17:38.187452Z",
     "iopub.status.idle": "2025-11-06T11:17:38.194618Z",
     "shell.execute_reply": "2025-11-06T11:17:38.194103Z",
     "shell.execute_reply.started": "2025-11-06T11:17:38.187727Z"
    }
   },
   "outputs": [],
   "source": [
    "class MoEFFN(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, n_expert=32, k=2, capacity_factor=1.25, lb_coef=0.01):\n",
    "        super().__init__()\n",
    "        self.router = TopKRouter(d_model, n_expert, k=k, lb_coef=lb_coef)\n",
    "        self.experts = nn.ModuleList([ExpertFFN(d_model, d_ff) for _ in range(n_expert)])\n",
    "        self.n_expert = n_expert\n",
    "        self.k = k\n",
    "        self.capacity_factor = capacity_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        topk_idx, combine, lb_loss = self.router(x)  # [B,T,k], [B,T,k], scalar\n",
    "        N = B * T\n",
    "        x_flat = x.reshape(N, D)                      # [N, D]\n",
    "        idx_flat = topk_idx.reshape(N, self.k)        # [N, k]\n",
    "        w_flat = combine.reshape(N, self.k)           # [N, k]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            counts = torch.zeros(self.n_expert, device=device, dtype=torch.int32)\n",
    "            for e in range(self.n_expert):\n",
    "                counts[e] = (idx_flat == e).sum()\n",
    "\n",
    "            expected = (N * self.k) / self.n_expert\n",
    "            capacity = int(self.capacity_factor * expected)\n",
    "\n",
    "        expert_inputs = [ [] for _ in range(self.n_expert) ]\n",
    "        expert_weights = [ [] for _ in range(self.n_expert) ]\n",
    "        expert_pos = [ [] for _ in range(self.n_expert) ]\n",
    "\n",
    "        cap_used = [0] * self.n_expert\n",
    "        for n in range(N):\n",
    "            for kk in range(self.k):\n",
    "                e = int(idx_flat[n, kk])\n",
    "                if cap_used[e] < capacity:\n",
    "                    expert_inputs[e].append(x_flat[n:n+1, :])   # [1, D]\n",
    "                    expert_weights[e].append(w_flat[n, kk:kk+1])# [1]\n",
    "                    expert_pos[e].append((n, kk))\n",
    "                    cap_used[e] += 1\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        out_flat = torch.zeros(N, D, device=device)\n",
    "        for e in range(self.n_expert):\n",
    "            if len(expert_inputs[e]) == 0:\n",
    "                continue\n",
    "            inp = torch.cat(expert_inputs[e], dim=0)           # [S_e, D]\n",
    "            wts = torch.cat(expert_weights[e], dim=0)          # [S_e, 1]\n",
    "            y = self.experts[e](inp)                           # [S_e, D]\n",
    "            for i, (n, kk) in enumerate(expert_pos[e]):\n",
    "                out_flat[n] += wts[i] * y[i]\n",
    "\n",
    "        out = out_flat.view(B, T, D)\n",
    "        aux_loss = lb_loss\n",
    "        return out, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee5d264f-6abb-4b52-b4fc-9a5994068e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:27:37.624192Z",
     "iopub.status.busy": "2025-11-06T11:27:37.623598Z",
     "iopub.status.idle": "2025-11-06T11:28:02.625340Z",
     "shell.execute_reply": "2025-11-06T11:28:02.624474Z",
     "shell.execute_reply.started": "2025-11-06T11:27:37.624168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(126.8601)\n",
      "loss: tensor(126.8588)\n",
      "loss: tensor(126.8575)\n",
      "loss: tensor(126.8587)\n",
      "loss: tensor(126.8586)\n",
      "loss: tensor(126.8576)\n",
      "loss: tensor(126.8565)\n",
      "loss: tensor(126.8541)\n",
      "loss: tensor(126.8572)\n",
      "loss: tensor(126.8577)\n"
     ]
    }
   ],
   "source": [
    "moe = MoEFFN(d_model=128, d_ff=512, n_expert=2, k=1, capacity_factor=1.2)\n",
    "moe.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    out, aux = moe(x)\n",
    "    loss = ((out - y) ** 2).mean() + aux\n",
    "    loss.backward()\n",
    "    print(\"loss:\", loss.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65766bc7-8e36-4447-84ff-02331878c8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
